{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joel's Pokemon Twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! So I decided that it would be neat to do some unsupervised learning on Pokemon tweets (since Pokemon Go has been so popular recently). This is my exploratory analysis on the tweets that I amassed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Connecting to Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to connect to Twitter's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import simplejson\n",
    "\n",
    "\n",
    "def values():\n",
    "    \"\"\"access_token = input(\"Please input access_token: \")\n",
    "    access_token_secret = input(\"Please input access_secret_token: \")\n",
    "    consumer_key = input(\"Please input consumer_key: \")\n",
    "    consumer_secret = input(\"Please input consumer_secret: \")\"\"\"\n",
    "\n",
    "    return(access_token, access_token_secret, consumer_key, consumer_secret)\n",
    "\n",
    "#Basic Listener\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    vals = []\n",
    "    def on_data(self, data):\n",
    "        #print data\n",
    "        print(data)\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #This handles Twitter Auth\n",
    "    data = []\n",
    "    try:\n",
    "        access_token, access_token_secret, consumer_key, consumer_secret = values()\n",
    "        listener = StdOutListener()\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        #This line filters twitter Streams to caputre keywords\n",
    "        stream.filter(track=[\"Pokemon Go\", \"pokemon\", \"Pokemon\"], languages=[\"en\"])\n",
    "    except KeyboardInterrupt:\n",
    "        #Press Control-C\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the way that I set this up was that I took the output of the python file (through the print() statments) and used as input to a text file. Here is the bash command that I used to run this.  \n",
    "\n",
    "python file_name.py > tweets.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Text Data to JSON  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tweets = []\n",
    "\n",
    "poke_tweet  = open(\"filename.txt\", \"r\")\n",
    "\n",
    "for line in poke_tweet:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "poke_tweet.close()\n",
    "with open(\"filename.json\", \"w\") as objectfile:\n",
    "    json.dump(tweets, objectfile, indent=4)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the K-Means Algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use the K-Means Clustering algorithm. The way that the algorithm works is that it takes a sample from the data and maps it to the closest cluster by using its mean. Here is the code that I used to train the K-Means Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "df = pd.read_json(\"/Users/Joel/Desktop/Tweets/final_poke_tweets.json\")\n",
    "text_data = df[\"text\"].fillna('')\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "final_text_data = vect.fit_transform(text_data)\n",
    "\n",
    "\n",
    "print('Training....')\n",
    "k = 5\n",
    "model = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(final_text_data)\n",
    "\n",
    "f = pickle.dump(model, open('/Users/Joel/Desktop/Tweets/kmeans_ipy.pkl','wb'))\n",
    "total_time = time.time() - start\n",
    "print(\"The algorithm ran in %3.f\" % total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ten Terms Per Cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "print('Top terms per cluster:')\n",
    "\n",
    "with open('/Users/Joel/Desktop/Tweets/kmeans_ipy.pkl', 'rb+') as f:\n",
    "    model = pickle.load(f)\n",
    "order_centroids = model.cluster_centers_.argsort()[:,::-1]\n",
    "terms = vect.get_feature_names()\n",
    "\n",
    "print(\"Top ten terms per cluster.\")\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d: \" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output: \n",
    "\n",
    "Top ten terms per cluster. \n",
    "Cluster0: \n",
    " pokemon\n",
    " https\n",
    " rt\n",
    " catch\n",
    " pokemongo\n",
    " playing\n",
    " like\n",
    " video\n",
    " youtube\n",
    " just\n",
    "\n",
    "Cluster1: \n",
    " people\n",
    " pokemon\n",
    " rt\n",
    " playing\n",
    " fact\n",
    " asap\n",
    " troubling\n",
    " deleting\n",
    " https\n",
    " like\n",
    "\n",
    "Cluster2: \n",
    " play\n",
    " pokemon\n",
    " rt\n",
    " https\n",
    " told\n",
    " omgtsn\n",
    " 1wontbddqv\n",
    " parents\n",
    " lol\n",
    " wanna\n",
    "\n",
    "Cluster3: \n",
    " rare\n",
    " rt\n",
    " https\n",
    " broken\n",
    " step\n",
    " nearby\n",
    " catchemali\n",
    " bmchh7mwn1\n",
    " qabriels\n",
    " takei\n",
    "\n",
    "Cluster4: \n",
    " rt\n",
    " glockachu\n",
    " yard\n",
    " 21savaage\n",
    " gone\n",
    " come\n",
    " trained\n",
    " looking\n",
    " night\n",
    " pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a new tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/Joel/Desktop/Tweets/kmeans_ipy.pkl', 'rb+') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "df = pd.read_json(\"/Users/Joel/Desktop/Tweets/final_poke_tweets.json\")\n",
    "text_data = df[\"text\"].fillna('')\n",
    "\n",
    "pred_tweet = \"Niantic Labs has made a public statement regarding their recent banning of accounts in\"\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "vec = vect.fit_transform(text_data)\n",
    "\n",
    "final_pred_data = vect.transform(pred_tweet.split('\\n'))\n",
    "\n",
    "prediction = model.predict(final_pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all I have for now. Later on I will be including visualizations. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
